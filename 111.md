# Demucs: Deep Extractor for Music Sources ê¸°ìˆ  ë¬¸ì„œ

## ğŸ“‹ ëª©ì°¨
1. [ì—°êµ¬ ê°œìš”](#1-ì—°êµ¬-ê°œìš”)
2. [ê¸°ìˆ ì  ë°°ê²½ ë° ë™ê¸°](#2-ê¸°ìˆ ì -ë°°ê²½-ë°-ë™ê¸°)
3. [ì•„í‚¤í…ì²˜ ì„¤ê³„](#3-ì•„í‚¤í…ì²˜-ì„¤ê³„)
4. [í•µì‹¬ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•](#4-í•µì‹¬-ì—”ì§€ë‹ˆì–´ë§-ê¸°ë²•)
5. [ì‹¤í—˜ ë° ì„±ëŠ¥ ë¶„ì„](#5-ì‹¤í—˜-ë°-ì„±ëŠ¥-ë¶„ì„)
6. [ê²°ë¡  ë° ì¸ì‚¬ì´íŠ¸](#6-ê²°ë¡ -ë°-ì¸ì‚¬ì´íŠ¸)

---

## 1. ì—°êµ¬ ê°œìš”

### 1.1 ì—°êµ¬ ëª©ì 
**ìŒì•… ì†ŒìŠ¤ ë¶„ë¦¬(Music Source Separation)**: í˜¼í•©ëœ ìŒì•… íŠ¸ë™(Mix)ì—ì„œ ê°œë³„ ì•…ê¸° íŠ¸ë™(Stems)ì„ ë¶„ë¦¬í•˜ëŠ” ê¸°ìˆ 

**ëª©í‘œ ì¶œë ¥:**
- ğŸ¥ Drums (ë“œëŸ¼)
- ğŸ¸ Bass (ë² ì´ìŠ¤)
- ğŸ¤ Vocals (ë³´ì»¬)
- ğŸ¹ Other (ê¸°íƒ€ ì•…ê¸° ë° ë°˜ì£¼)

### 1.2 í•µì‹¬ ë¬¸ì œ
ì¸ê°„ì˜ ì²­ê° ì‹œìŠ¤í…œì´ ê°€ì§„ "ì¹µí…Œì¼ íŒŒí‹° íš¨ê³¼(Cocktail Party Effect)" - ì‹œë„ëŸ¬ìš´ í™˜ê²½ì—ì„œë„ íŠ¹ì • ì†Œë¦¬ì— ì§‘ì¤‘í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ - ë¥¼ ê¸°ê³„ì ìœ¼ë¡œ êµ¬í˜„

### 1.3 ì—°êµ¬ ì˜ì˜
- Facebook AI Research(FAIR)ì—ì„œ ë°œí‘œ
- Waveform ë„ë©”ì¸ ë”¥ëŸ¬ë‹ì˜ ìƒˆë¡œìš´ ê°€ëŠ¥ì„± ì œì‹œ
- ì´ë¡ ì  ìƒí•œì„ (Oracle)ì„ ì´ˆê³¼í•˜ëŠ” ì‹¤ì¦ì  ì„±ê³¼

---

## 2. ê¸°ìˆ ì  ë°°ê²½ ë° ë™ê¸°

### 2.1 ê¸°ì¡´ ì ‘ê·¼ë²•ì˜ ë¶„ë¥˜

#### **A. Spectrogram ê¸°ë°˜ ë°©ì‹ (ì£¼ë¥˜)**

**ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:**
```
ì…ë ¥ Waveform 
    â†“
STFT (Short-Time Fourier Transform)
    â†“
Spectrogram (ì£¼íŒŒìˆ˜ ë„ë©”ì¸)
    â†“
Neural Network (ë§ˆìŠ¤í¬ ìƒì„±)
    â†“
Masked Spectrogram
    â†“
iSTFT (ì—­ë³€í™˜)
    â†“
ì¶œë ¥ Waveform
```

**ëŒ€í‘œ ëª¨ë¸:**
- NMF (Non-negative Matrix Factorization)
- Open-Unmix (LSTM ê¸°ë°˜)
- MMDenseLSTM
- D3Net (ë‹¹ì‹œ SOTA, SDR 6.0)
- Spleeter (ì‚°ì—…ê³„ì—ì„œ ë„ë¦¬ ì‚¬ìš©, U-Net ê¸°ë°˜)

**ì¥ì :**
- ì£¼íŒŒìˆ˜ íŠ¹ì„±ì´ ëª…í™•í•œ ì•…ê¸°(ë³´ì»¬ ë“±) ë¶„ë¦¬ì— ìœ ë¦¬
- ë°°ìŒ(Harmonics) êµ¬ì¡° í™œìš© ê°€ëŠ¥
- ì•ˆì •ì ì¸ í•™ìŠµ

**ê·¼ë³¸ì  í•œê³„:**
- **ìœ„ìƒ(Phase) ë³µì› ë¬¸ì œ**: STFTëŠ” í¬ê¸°(Magnitude)ì™€ ìœ„ìƒ(Phase)ìœ¼ë¡œ ë¶„í•´ë˜ëŠ”ë°, ë§ˆìŠ¤í‚¹ì€ ì£¼ë¡œ í¬ê¸°ì—ë§Œ ì ìš©ë¨
- ìœ„ìƒ ì •ë³´ì˜ ë¶€ì •í™•í•œ ë³µì› â†’ ìŒì§ˆ ì €í•˜
- ì´ë¡ ì  ìƒí•œì„  ì¡´ì¬ (IRM Oracle)

#### **B. Waveform ê¸°ë°˜ ë°©ì‹ (ë„ì „ì )**

**ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:**
```
ì…ë ¥ Waveform
    â†“
Neural Network (End-to-End)
    â†“
ì¶œë ¥ Waveform
```

**ëŒ€í‘œ ëª¨ë¸:**
- Wave-U-Net (ì´ˆê¸° ì‹œë„, SDR 3.2)
- Conv-Tasnet (ìŒì„± ë¶„ë¦¬ìš©, ìŒì•…ì—ì„œëŠ” ì‹¤íŒ¨)

**ì¥ì :**
- ìœ„ìƒ ë¬¸ì œ ì›ì²œì  í•´ê²°
- End-to-End í•™ìŠµ ê°€ëŠ¥
- ì´ë¡ ì ìœ¼ë¡œ ë” ì •í™•í•œ ë³µì› ê°€ëŠ¥

**ê¸°ì¡´ í•œê³„:**
- ë°ì´í„° ì°¨ì› í­ë°œ (44.1kHz â†’ 1ì´ˆë‹¹ 44,100 í¬ì¸íŠ¸)
- í•™ìŠµ ë¶ˆì•ˆì •
- ì„±ëŠ¥ ì €ì¡° (Spectrogram ëŒ€ë¹„ 40% ë‚®ì€ SDR)

---

### 2.2 Conv-Tasnetì˜ ì‹¤íŒ¨ ì‚¬ë¡€ ë¶„ì„

#### **ë°°ê²½**
- ìŒì„± ë¶„ë¦¬(Speech Separation)ì—ì„œ í° ì„±ê³µì„ ê±°ë‘” ëª¨ë¸
- 8kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸, ì§§ì€ ë°œí™”(utterance) ì²˜ë¦¬ì— ìµœì í™”

#### **ìŒì•… ë„ë©”ì¸ ì ìš© ì‹œ ë¬¸ì œì **

**1. ì•„í‹°íŒ©íŠ¸(Artifacts) ë°œìƒ**
- ì²­ê°ì ìœ¼ë¡œ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ì¡ìŒ
- ê´‘ëŒ€ì—­ ë…¸ì´ì¦ˆ(Broadband noise)
- "ë¹ˆ ê¹¡í†µ" ê°™ì€ ê¸ˆì†ì„± ì†Œë¦¬
- í‹±í‹±ê±°ë¦¬ëŠ” í´ë¦­ ë…¸ì´ì¦ˆ

**2. ì£¼ìš” ìŒ ëˆ„ë½ (Figure 1ì˜ í•µì‹¬)**
```
[Ground Truth]     [Conv-Tasnet]      [Demucs]
  ë² ì´ìŠ¤ ìŒ â—  â†’    ë² ì´ìŠ¤ ìŒ X    â†’   ë² ì´ìŠ¤ ìŒ â—
  (ì •ë‹µ)              (ì™„ì „ ì†Œì‹¤)        (ì •í™•íˆ ë³µì›)
```
â†’ ìˆ˜ì¹˜ì  ì„±ëŠ¥(SDR)ì€ ë†’ì•„ë„ ì‹¤ì œ ë“¤ìœ¼ë©´ ì¤‘ìš”í•œ ìŒì´ ì‚¬ë¼ì§

**3. ìƒ˜í”Œë§ ë ˆì´íŠ¸ ë¬¸ì œ**
- 8kHz â†’ 44.1kHz: ì•½ 5.5ë°° ë°ì´í„° ë°€ë„ ì¦ê°€
- ë™ì¼í•œ ì‹œê°„ ì •ë³´ë¥¼ ë³´ë ¤ë©´ Receptive Field í™•ì¥ í•„ìš”

**4. ê¸´ ìŒì•… íŠ¸ë™ ì²˜ë¦¬ ë¬¸ì œ**
- Global Layer Normalizationì˜ ë¶€ì‘ìš©
- ì¡°ìš©í•œ êµ¬ê°„ê³¼ ì‹œë„ëŸ¬ìš´ êµ¬ê°„ì˜ ë³¼ë¥¨ ìŠ¤ì¼€ì¼ë§ ì™œê³¡

#### **ì‹œë„í•œ ìµœì í™” (ê·¸ëŸ¬ë‚˜ ê·¼ë³¸ì  í•´ê²° ì‹¤íŒ¨)**

| í•­ëª© | ì›ë³¸ (Speech) | ìŒì•…ìš© ìˆ˜ì • | ë¹„ê³  |
|------|---------------|------------|------|
| **Loss Function** | SI-SNR | L1 Loss | íŒŒí˜• ê±°ë¦¬ ìµœì†Œí™”ê°€ ë” íš¨ê³¼ì  |
| **Kernel Size** | 16 | 20 | Receptive Field 1.5ì´ˆ ìœ ì§€ |
| **Stride** | 8 | 10 | ìƒ˜í”Œë§ ë ˆì´íŠ¸ ëŒ€ì‘ |
| **ì¶”ë¡  ë°©ì‹** | Full track | 8ì´ˆ Chunking | Global Norm ë¬¸ì œ íšŒí”¼ |

**ê²°ê³¼:** ìˆ˜ì¹˜ ê°œì„ ì€ ìˆì—ˆìœ¼ë‚˜ ì•„í‹°íŒ©íŠ¸ ë¬¸ì œëŠ” í•´ê²° ë¶ˆê°€ â†’ **ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ í•„ìš”ì„± ëŒ€ë‘**

---

## 3. ì•„í‚¤í…ì²˜ ì„¤ê³„

### 3.1 ì „ì²´ êµ¬ì¡° (Macro Architecture)

```
                    ì…ë ¥: Mixture Waveform [B, 1, T]
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    ENCODER (6 Layers)                    â”‚
    â”‚  Conv1d(K=8, S=4) + GLU + Conv1d(K=3) + GLU             â”‚
    â”‚                                                          â”‚
    â”‚  Layer 1: [B, 1, T]      â†’ [B, 64, T/4]    â”€â”€â”         â”‚
    â”‚  Layer 2: [B, 64, T/4]   â†’ [B, 128, T/16]  â”€â”€â”¼â”€â”       â”‚
    â”‚  Layer 3: [B, 128, T/16] â†’ [B, 256, T/64]  â”€â”€â”¼â”€â”¼â”€â”     â”‚
    â”‚  Layer 4: [B, 256, T/64] â†’ [B, 512, T/256] â”€â”€â”¼â”€â”¼â”€â”¼â”€â”   â”‚
    â”‚  Layer 5: [B, 512, T/256]â†’ [B, 1024, T/1K] â”€â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â” â”‚
    â”‚  Layer 6: [B, 1024, T/1K]â†’ [B, 2048, T/4K] â”€â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”˜
                              â†“                    â”‚ â”‚ â”‚ â”‚ â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”
    â”‚              BOTTLENECK (Bi-LSTM)           â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
    â”‚  - 2 Layers Bidirectional LSTM              â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
    â”‚  - Hidden size: 2048                        â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
    â”‚  - ì¥ê¸° ì‹œê³„ì—´ ë¬¸ë§¥ í•™ìŠµ                     â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”˜
                              â†“                    â”‚ â”‚ â”‚ â”‚ â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”
    â”‚                 DECODER (6 Layers)          â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
    â”‚  TransposedConv1d(K=8, S=4) + GLU + ...     â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
    â”‚                                              â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
    â”‚  Layer 6: [B, 2048, T/4K]â†’ [B, 1024, T/1K] â†â”˜ â”‚ â”‚ â”‚ â”‚ â”‚
    â”‚  Layer 5: [B, 1024, T/1K]â†’ [B, 512, T/256] â†â”€â”€â”˜ â”‚ â”‚ â”‚ â”‚
    â”‚  Layer 4: [B, 512, T/256]â†’ [B, 256, T/64]  â†â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚
    â”‚  Layer 3: [B, 256, T/64] â†’ [B, 128, T/16]  â†â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
    â”‚  Layer 2: [B, 128, T/16] â†’ [B, 64, T/4]    â†â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚  Layer 1: [B, 64, T/4]   â†’ [B, 4, T]       â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
              ì¶œë ¥: 4 Stems [B, 4, T] (Drums, Bass, Vocals, Other)
```

### 3.2 í•µì‹¬ ì„¤ê³„ ì›ì¹™

#### **1. U-Net Backbone**
**ì„ íƒ ì´ìœ :**
- ì˜ë£Œ ì˜ìƒ ë¶„í• (Segmentation)ì—ì„œ ê²€ì¦ëœ êµ¬ì¡°
- ê³µê°„ì (ì—¬ê¸°ì„œëŠ” ì‹œê°„ì ) ì •ë³´ ë³´ì¡´ì— íƒì›”
- Skip Connectionì„ í†µí•œ ë‹¤ì¤‘ í•´ìƒë„ íŠ¹ì§• ìœµí•©

**ì˜¤ë””ì˜¤ì— ë§ì¶˜ ìˆ˜ì •:**
- ì´ë¯¸ì§€: Stride 2 (ë³´í†µ 256Ã—256 â†’ 128Ã—128)
- **ì˜¤ë””ì˜¤: Stride 4** (44,100 í¬ì¸íŠ¸/ì´ˆ â†’ ê¸‰ê²©í•œ ì°¨ì› ì¶•ì†Œ í•„ìš”)

**Skip Connectionì˜ ì—­í• :**
```python
# ì˜ì‚¬ì½”ë“œ
encoder_output = encoder_layer(x)  # [B, C, T]
decoder_input = decoder_layer(bottleneck)  # [B, C, T]
decoder_output = decoder_input + encoder_output  # Element-wise addition
```
â†’ ì••ì¶• ê³¼ì •ì—ì„œ ì†ì‹¤ëœ ê³ ì£¼íŒŒ ë””í…Œì¼ + ìœ„ìƒ ì •ë³´ ë³µì›

---

#### **2. Bi-LSTM Bottleneck**

**ë¬¸ì œ ì¸ì‹:**
- CNNì€ êµ­ì†Œì  íŒ¨í„´(Local patterns) í•™ìŠµì— ê°•í•¨
- í•˜ì§€ë§Œ ìŒì•…ì€ **ì¥ê¸° ì˜ì¡´ì„±(Long-term dependency)** ì¤‘ìš”
  - ì˜ˆ: ì½”ëŸ¬ìŠ¤ê°€ ë°˜ë³µë˜ëŠ” êµ¬ì¡°
  - ì˜ˆ: ì „ì£¼ì™€ í›„ì£¼ì˜ ê´€ê³„
  - ì˜ˆ: í…œí¬, ë¦¬ë“¬ì˜ ì¼ê´€ì„±

**í•´ê²°ì±…:**
```
Bottleneck = Bi-LSTM(
    input_size=2048,
    hidden_size=2048,
    num_layers=2,
    bidirectional=True
)
```

**ì–‘ë°©í–¥(Bidirectional)ì˜ ì¤‘ìš”ì„±:**
- Forward LSTM: ê³¼ê±° ì •ë³´ í™œìš©
- Backward LSTM: ë¯¸ë˜ ì •ë³´ í™œìš©
- ìŒì•…ì€ ì•ë’¤ ë¬¸ë§¥ì„ ëª¨ë‘ ê³ ë ¤í•´ì•¼ ì •í™•í•œ ë¶„ë¦¬ ê°€ëŠ¥

**íŠ¸ë ˆì´ë“œì˜¤í”„:**
- ì—°ì‚°ëŸ‰ ì¦ê°€ (ìˆœì°¨ ì²˜ë¦¬ í•„ìš”)
- í•˜ì§€ë§Œ Bottleneckë§Œ LSTM ì‚¬ìš© â†’ ì „ì²´ ì—°ì‚°ëŸ‰ì€ ê´€ë¦¬ ê°€ëŠ¥

---

#### **3. GLU (Gated Linear Units)**

**ê¸°ì¡´ í™œì„±í™” í•¨ìˆ˜ì˜ ë¬¸ì œ:**
- ReLU: ìŒìˆ˜ ì˜ì—­ ì •ë³´ ì†ì‹¤
- Tanh: Gradient vanishing
- Batch Norm ì œê±° í›„ í•™ìŠµ ë¶ˆì•ˆì •

**GLU ë©”ì»¤ë‹ˆì¦˜:**
```python
def GLU(x):
    # x shape: [B, 2C, T]
    a, b = x.chunk(2, dim=1)  # ì±„ë„ ë°©í–¥ìœ¼ë¡œ ì ˆë°˜ì”© ë¶„ë¦¬
    # a: [B, C, T] - ì„ í˜• ë³€í™˜
    # b: [B, C, T] - ê²Œì´íŠ¸ ì‹ í˜¸
    return a * sigmoid(b)  # [B, C, T]
```

**ì‘ë™ ì›ë¦¬:**
```
Conv1d(C â†’ 2C, K=3)  # ì±„ë„ 2ë°° í™•ì¥
    â†“
[Linear part (C)] [Gate part (C)]
    â†“                 â†“
    a          Ã—    Ïƒ(b)
    â†“
  Output (C)
```

**ì¥ì :**
- **ì ì‘ì  ì •ë³´ í•„í„°ë§**: ì¤‘ìš”í•œ íŠ¹ì§•ì€ í†µê³¼, ë¶ˆí•„ìš”í•œ íŠ¹ì§•ì€ ì–µì œ
- Gradient flow ê°œì„ 
- Batch Norm ì—†ì´ë„ ì•ˆì •ì  í•™ìŠµ

**ì‹¤ì œ íš¨ê³¼:**
- ì´ˆê¸° ì‹¤í—˜ì—ì„œ ReLU ëŒ€ë¹„ **0.2 SDR í–¥ìƒ**
- ë„¤íŠ¸ì›Œí¬ ê¹Šì–´ì ¸ë„ í•™ìŠµ ì•ˆì •ì„± ìœ ì§€

---

### 3.3 ì„¸ë¶€ ë¸”ë¡ êµ¬ì¡° (Micro Architecture)

#### **Encoder Block**
```python
class EncoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        # 1. Downsampling
        self.downsample = nn.Conv1d(
            in_channels, out_channels,
            kernel_size=8, stride=4, padding=2
        )
        self.glu1 = GLU(out_channels)
        
        # 2. Refinement
        self.conv = nn.Conv1d(
            out_channels, out_channels * 2,
            kernel_size=3, padding=1
        )
        self.glu2 = GLU(out_channels * 2)
    
    def forward(self, x):
        x = self.downsample(x)
        x = self.glu1(x)
        x = self.conv(x)
        x = self.glu2(x)
        return x
```

**ì„¤ê³„ ì˜ë„:**
1. **Aggressive downsampling** (Stride=4)
   - ë©”ëª¨ë¦¬ íš¨ìœ¨: 44,100 í¬ì¸íŠ¸/ì´ˆë¥¼ ë¹ ë¥´ê²Œ ì••ì¶•
   - Receptive field í™•ì¥: ë” ë„“ì€ ì‹œê°„ ë²”ìœ„ ê´€ì°°

2. **GLU ì´ì¤‘ ì ìš©**
   - ì²« ë²ˆì§¸: Downsampling í›„ ì •ë³´ ì •ì œ
   - ë‘ ë²ˆì§¸: Refinement convolution í›„ íŠ¹ì§• ì„ íƒ

---

#### **Decoder Block**
```python
class DecoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        # 1. Refinement (ë¨¼ì € ìˆ˜í–‰)
        self.conv = nn.Conv1d(
            in_channels, in_channels * 2,
            kernel_size=3, padding=1
        )
        self.glu1 = GLU(in_channels * 2)
        
        # 2. Upsampling
        self.upsample = nn.ConvTranspose1d(
            in_channels, out_channels,
            kernel_size=8, stride=4, padding=2
        )
        self.glu2 = GLU(out_channels)
    
    def forward(self, x, skip):
        # Skip connection ì¶”ê°€
        x = x + skip
        x = self.conv(x)
        x = self.glu1(x)
        x = self.upsample(x)
        x = self.glu2(x)
        return x
```

**Encoderì™€ì˜ ëŒ€ì¹­ì„±:**
- Encoder: Downsample â†’ GLU â†’ Conv â†’ GLU
- Decoder: Conv â†’ GLU â†’ Upsample â†’ GLU
- ì •ë³´ íë¦„ì˜ ê· í˜• ìœ ì§€

---

### 3.4 ì±„ë„ ìˆ˜ ì¦ê°€ ì „ëµ

```
Layer    Channels    Feature Map Size    ì—­í• 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input       1         T (44,100/sec)    ì›ë³¸ íŒŒí˜•
Enc-1      64         T/4               ì €ìˆ˜ì¤€ íŠ¹ì§• (Attack, í„ìŠ¤)
Enc-2     128         T/16              ì¤‘ê°„ íŠ¹ì§• (ë¦¬ë“¬ íŒ¨í„´)
Enc-3     256         T/64              ê³ ìˆ˜ì¤€ íŠ¹ì§• (í™”ìŒ)
Enc-4     512         T/256             ì˜ë¯¸ë¡ ì  íŠ¹ì§• (ì•…ê¸° íŠ¹ì„±)
Enc-5    1024         T/1,024           ì¶”ìƒì  í‘œí˜„
Enc-6    2048         T/4,096           ìµœëŒ€ ì••ì¶•
LSTM     2048         T/4,096           ì‹œê³„ì—´ ë¬¸ë§¥
Dec-6    1024         T/1,024           ì¬êµ¬ì„± ì‹œì‘
Dec-5     512         T/256             ì„¸ë¶€ íŠ¹ì§• ë³µì›
Dec-4     256         T/64              ì¤‘ê°„ í•´ìƒë„ ë³µì›
Dec-3     128         T/16              ë¦¬ë“¬ ë³µì›
Dec-2      64         T/4               ê³ ì£¼íŒŒ ë³µì›
Dec-1       4         T                 4ê°œ Stems ì¶œë ¥
```

**ì„¤ê³„ ì² í•™:**
- **ì§€ìˆ˜ì  ì¦ê°€**: 1 â†’ 64 â†’ 128 â†’ ... â†’ 2048
- **í‘œí˜„ë ¥ í™•ë³´**: ê¹Šì´ ê°ˆìˆ˜ë¡ ë” ë§ì€ ì±„ë„ë¡œ ë³µì¡í•œ íŠ¹ì§• í‘œí˜„
- **ëŒ€ì¹­ì  ê°ì†Œ**: ë””ì½”ë”ëŠ” ì—­ìˆœìœ¼ë¡œ ê°ì†Œ

---

## 4. í•µì‹¬ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•

### 4.1 Weight Rescaling (ì´ˆê¸°í™” ì „ëµ)

#### **ë°œê²¬ëœ ë¬¸ì œ**
```python
# ì´ˆê¸° ì‹¤í—˜ ê´€ì°°
model = Demucs()
x = torch.randn(1, 1, 44100)  # 1ì´ˆ ì˜¤ë””ì˜¤

with torch.no_grad():
    # Kaiming ì´ˆê¸°í™”ë§Œ ì‚¬ìš©
    output = model(x)
    
print(x.abs().mean())       # ì•½ 0.5
print(output.abs().mean())  # ì•½ 0.025 (1/20 ìˆ˜ì¤€!)
```

**ì›ì¸ ë¶„ì„:**
- ê¹Šì€ ë„¤íŠ¸ì›Œí¬: 6 layers Ã— 2 (encoder + decoder)
- ê° ë ˆì´ì–´ í†µê³¼ ì‹œë§ˆë‹¤ ë¶„ì‚° ê°ì†Œ
- ìµœì¢… ì¶œë ¥ì˜ ìŠ¤ì¼€ì¼ì´ ì…ë ¥ ëŒ€ë¹„ ë„ˆë¬´ ì‘ìŒ
- Gradientê°€ ì´ˆê¸° ë ˆì´ì–´ê¹Œì§€ ì „íŒŒë˜ê¸° ì–´ë ¤ì›€

---

#### **í•´ê²° ë°©ë²•: Rescaling**

```python
def rescale_module(module, reference):
    """
    ëª¨ë“ˆì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ì—¬ ì¶œë ¥ ìŠ¤ì¼€ì¼ ìœ ì§€
    
    Args:
        module: nn.Module (Conv, Linear ë“±)
        reference: ëª©í‘œ ì¶œë ¥ ìŠ¤ì¼€ì¼
    """
    with torch.no_grad():
        # 1. í˜„ì¬ ì¶œë ¥ ìŠ¤ì¼€ì¼ ì¸¡ì •
        x = torch.randn(8, module.in_channels, 1000)
        out = module(x)
        scale = out.std()
        
        # 2. ê°€ì¤‘ì¹˜ ì¡°ì •
        rescale = reference / scale
        module.weight.data *= rescale
        if module.bias is not None:
            module.bias.data *= rescale

# ì „ì²´ ë„¤íŠ¸ì›Œí¬ì— ì ìš©
for module in model.modules():
    if isinstance(module, (nn.Conv1d, nn.ConvTranspose1d)):
        rescale_module(module, reference=1.0)
```

**íš¨ê³¼:**
```
Before rescaling:
  Layer 1 output std: 1.0
  Layer 6 output std: 0.05
  
After rescaling:
  Layer 1 output std: 1.0
  Layer 6 output std: 0.9  â† ìŠ¤ì¼€ì¼ ìœ ì§€!
```

**í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ:**
- ì´ˆê¸° loss ê°ì†Œ ì†ë„ **2ë°° í–¥ìƒ**
- ìµœì¢… SDR **+0.3 í–¥ìƒ**
- Gradient vanishing ë¬¸ì œ ì™„í™”

---

### 4.2 The "Shift Trick" (ì¶”ë¡  ìµœì í™”)

#### **ì´ë¡ ì  ë°°ê²½: Time Equivariance**

**ì •ì˜:**
```
f(shift(x, t)) = shift(f(x), t)
```
ì¦‰, ì…ë ¥ì„ ì‹œê°„ì¶•ìœ¼ë¡œ ì´ë™ì‹œí‚¤ë©´ ì¶œë ¥ë„ ë™ì¼í•˜ê²Œ ì´ë™í•´ì•¼ í•¨

**í˜„ì‹¤:**
```python
x = load_audio("song.wav")
y1 = model(x)
y2 = model(x[100:])  # 100 ìƒ˜í”Œ shift

# ì´ë¡ : y1[100:] == y2 ì—¬ì•¼ í•¨
# ì‹¤ì œ: ìƒë‹¹í•œ ì°¨ì´ ë°œìƒ!
```

**ì›ì¸:**
- Convolutionì˜ padding íš¨ê³¼
- Stride ì—°ì‚°ì˜ ê²½ê³„ ì²˜ë¦¬
- Poolingì˜ ìœ„ì¹˜ ì˜ì¡´ì„±

---

#### **Shift Trick ì•Œê³ ë¦¬ì¦˜**

```python
def shift_trick_inference(model, audio, num_shifts=10):
    """
    ì—¬ëŸ¬ ë²ˆ shiftí•˜ì—¬ ì•™ìƒë¸”
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        audio: ì…ë ¥ ì˜¤ë””ì˜¤ [T]
        num_shifts: shift íšŸìˆ˜
    
    Returns:
        averaged output [4, T]
    """
    outputs = []
    
    for i in range(num_shifts):
        # 1. ëœë¤ shift ì–‘ ê²°ì •
        shift_amount = random.randint(0, model.stride ** model.num_layers)
        
        # 2. ì…ë ¥ shift (padding ì¶”ê°€)
        shifted_input = torch.nn.functional.pad(
            audio, (shift_amount, 0), mode='constant'
        )
        
        # 3. ëª¨ë¸ ì¶”ë¡ 
        shifted_output = model(shifted_input)
        
        # 4. ì¶œë ¥ ì—­shift (ì›ë˜ ìœ„ì¹˜ë¡œ)
        output = shifted_output[:, :, shift_amount:]
        outputs.append(output)
    
    # 5. í‰ê· 
    return torch.stack(outputs).mean(dim=0)
```

**ì‹œê°í™”:**
```
Shift 0:  [Audio      ] â†’ Model â†’ [Output     ]
Shift 50: [  Audio    ] â†’ Model â†’ [  Output   ] â†’ Reverse shift
Shift 100:[    Audio  ] â†’ Model â†’ [    Output ] â†’ Reverse shift
...
Final: Average of all outputs
```

**íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„:**

| Shift íšŸìˆ˜ | ì¶”ë¡  ì‹œê°„ | SDR í–¥ìƒ | ì‹¤ìš©ì„± |
|-----------|----------|---------|--------|
| 1 (No shift) | 1x | 0.0 | âœ… ì‹¤ì‹œê°„ ê°€ëŠ¥ |
| 5 | 5x | +0.25 | âœ… ì¤€ì‹¤ì‹œê°„ |
| 10 | 10x | +0.30 | âš ï¸ ì˜¤í”„ë¼ì¸ |
| 20 | 20x | +0.32 | âŒ ë¹„íš¨ìœ¨ì  |

**ê¶Œì¥ ì„¤ì •:**
- ì‹¤ì‹œê°„ ì‘ìš©: shift=1
- ê³ í’ˆì§ˆ í”„ë¡œë•ì…˜: shift=10

---

### 4.3 Resampling Trick

#### **ê¸°ë²• ì„¤ëª…**
```python
def resampling_trick(model, audio, sample_rate=44100):
    """
    Upsampling â†’ ëª¨ë¸ ì²˜ë¦¬ â†’ Downsampling
    """
    # 1. 2ë°° Upsampling
    audio_2x = torchaudio.functional.resample(
        audio, sample_rate, sample_rate * 2
    )
    
    # 2. ëª¨ë¸ ì¶”ë¡  (2ë°° í•´ìƒë„)
    output_2x = model(audio_2x)
    
    # 3. ì›ë˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¡œ ë³µì›
    output = torchaudio.functional.resample(
        output_2x, sample_rate * 2, sample_rate
    )
    
    return output
```

#### **ì‹ í˜¸ì²˜ë¦¬ ì´ë¡ ì  ê·¼ê±°**

**ë‚˜ì´í€´ìŠ¤íŠ¸ ì •ë¦¬:**
- ìƒ˜í”Œë§ ë ˆì´íŠ¸ = 44.1kHz
- í‘œí˜„ ê°€ëŠ¥í•œ ìµœëŒ€ ì£¼íŒŒìˆ˜ = 22.05kHz
- ê·¸ ì´ìƒì€ Aliasing ë°œìƒ

**Upsamplingì˜ íš¨ê³¼:**
- 88.2kHzë¡œ upsampling
- ìµœëŒ€ ì£¼íŒŒìˆ˜ = 44.1kHz
- ëª¨ë¸ì´ ë” ì„¸ë°€í•œ ê³ ì£¼íŒŒ ì •ë³´ ì²˜ë¦¬ ê°€ëŠ¥
- Aliasing ì•„í‹°íŒ©íŠ¸ ê°ì†Œ

**ì‹¤í—˜ ê²°ê³¼:**
```
No resampling:     SDR 6.3
With resampling:   SDR 6.5  (+0.2)
```

**ì£¼ì˜ì‚¬í•­:**
- ì¶”ë¡  ì‹œê°„ ì•½ **3ë°° ì¦ê°€**
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ **2ë°° ì¦ê°€**
- ê³ í’ˆì§ˆì´ ì¤‘ìš”í•œ ê²½ìš°ë§Œ ì‚¬ìš© ê¶Œì¥

---

### 4.4 Loss Function ì„¤ê³„

#### **í›„ë³´ Loss Functions ë¹„êµ**

**1. L2 Loss (MSE)**
```python
def l2_loss(pred, target):
    return torch.mean((pred - target) ** 2)
```
- íŠ¹ì§•: í° ì—ëŸ¬ì— í° í˜ë„í‹°
- ë¬¸ì œ: ê³¼ë„í•˜ê²Œ smoothí•œ ì¶œë ¥ ê²½í–¥

**2. L1 Loss (MAE) âœ… ì±„íƒ**
```python
def l1_loss(pred, target):
    return torch.mean(torch.abs(pred - target))
```
- íŠ¹ì§•: ëª¨ë“  ì—ëŸ¬ì— ê· ë“±í•œ í˜ë„í‹°
- ì¥ì : íŒŒí˜•ì˜ sharpí•œ íŠ¹ì§•(attack) ë³´ì¡´
- ì‹¤í—˜ ê²°ê³¼: **L2 ëŒ€ë¹„ +0.1 SDR**

**3. SI-SNR (Scale-Invariant SNR)**
```python
def si_snr(pred, target):
    # ìŠ¤ì¼€ì¼ ë¶ˆë³€ì„± í™•ë³´
    target_norm = target / torch.norm(target)
    pred_proj = (pred * target_norm).sum() * target_norm
    noise = pred - pred_proj
    return -10 * torch.log10(
        torch.norm(pred_proj) / torch.norm(noise)
    )
```
- Conv-Tasnetì—ì„œ ì‚¬ìš©
- ìŒì•…ì—ì„œëŠ” **L1ë³´ë‹¤ 0.2 SDR ë‚®ìŒ**

---

#### **ìµœì¢… ì„ íƒ: L1 Lossì˜ ì´ìœ **

**1. íŒŒí˜• íŠ¹ì„± ë³´ì¡´**
```
ë“œëŸ¼ì˜ Attack (ìˆœê°„ì ì¸ í° ì§„í­):
  L2: [0.5, 0.6, 0.7, 0.6, 0.5] â† ë­‰ê°œì§
  L1: [0.0, 0.1, 1.0, 0.1, 0.0] â† Sharpí•˜ê²Œ ìœ ì§€
```

**2. ìˆ˜ì¹˜ì  ì•ˆì •ì„±**
```python
# L2ì˜ ë¬¸ì œ
error = pred - target  # [-1.0, 0.1, 0.05, ...]
squared = error ** 2   # [1.0, 0.01, 0.0025, ...]
# í° ì—ëŸ¬ê°€ ì§€ë°°ì  â†’ ì‘ì€ ë””í…Œì¼ ë¬´ì‹œ

# L1ì˜ ê· í˜•
abs_error = abs(error)  # [1.0, 0.1, 0.05, ...]
# ëª¨ë“  ì—ëŸ¬ê°€ ê· ë“±í•˜ê²Œ ê¸°ì—¬
```

**3. ì‹¤í—˜ì  ê²€ì¦**
```
Dataset: MUSDB18
Metric: SDR (Signal-to-Distortion Ratio)

L2 Loss:     6.2 SDR
L1 Loss:     6.3 SDR  âœ…
SI-SNR:      6.1 SDR
```

---

### 4.5 Chunking Strategy (ì¶”ë¡  ìµœì í™”)

#### **ë¬¸ì œ ìƒí™©**
```python
# ì „ì²´ ë…¸ë˜ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
song = load_audio("5min_song.wav")  # Shape: [13,230,000]
output = model(song)  # OOM! ë˜ëŠ” í’ˆì§ˆ ì €í•˜
```

**ì›ì¸:**
1. **ë©”ëª¨ë¦¬**: 5ë¶„ ë…¸ë˜ = 1320ë§Œ ìƒ˜í”Œ â†’ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
2. **Global Layer Norm**: ì „ì²´ ë…¸ë˜ì˜ í†µê³„ë¡œ ì •ê·œí™” â†’ ë³¼ë¥¨ ì™œê³¡

**Global Normì˜ ë¬¸ì œ:**
```
ì¡°ìš©í•œ ì¸íŠ¸ë¡œ (0~30ì´ˆ): í‰ê·  ì§„í­ 0.1
ì‹œë„ëŸ¬ìš´ ì½”ëŸ¬ìŠ¤ (1~2ë¶„): í‰ê·  ì§„í­ 0.8

Global mean = (0.1 + 0.8) / 2 = 0.45
â†’ ì¸íŠ¸ë¡œê°€ ê³¼ë„í•˜ê²Œ ì¦í­ë¨
â†’ ì½”ëŸ¬ìŠ¤ê°€ ê³¼ë„í•˜ê²Œ ê°ì†Œë¨
```

---

#### **í•´ê²°: 8ì´ˆ Chunking**

```python
def chunked_inference(model, audio, chunk_size=8, overlap=1):
    """
    Args:
        chunk_size: ì²­í¬ ê¸¸ì´ (ì´ˆ)
        overlap: ê²¹ì¹¨ ì˜ì—­ (ì´ˆ)
    """
    sr = 44100
    chunk_samples = chunk_size * sr
    overlap_samples = overlap * sr
    hop = chunk_samples - overlap_samples
    
    outputs = []
    for start in range(0, len(audio), hop):
        # 1. ì²­í¬ ì¶”ì¶œ
        end = start + chunk_samples
        chunk = audio[start:end]
        
        # 2. ì²­í¬ë³„ ì²˜ë¦¬
        chunk_output = model(chunk)
        
        # 3. Overlap ì˜ì—­ ì²˜ë¦¬
        if len(outputs) > 0:
            # ì´ì „ ì²­í¬ì™€ í¬ë¡œìŠ¤í˜ì´ë“œ
            prev_end = outputs[-1][:, -overlap_samples:]
            curr_start = chunk_output[:, :overlap_samples]
            blended = crossfade(prev_end, curr_start)
            outputs[-1] = outputs[-1][:, :-overlap_samples]
            chunk_output[:, :overlap_samples] = blended
        
        outputs.append(chunk_output)
    
    return torch.cat(outputs, dim=-1)

def crossfade(a, b, alpha=0.5):
    """ì„ í˜• í¬ë¡œìŠ¤í˜ì´ë“œ"""
    weight = torch.linspace(0, 1, len(a))
    return a * (1 - weight) + b * weight
```

**ì‹œê°í™”:**
```
ì „ì²´ ë…¸ë˜: [=================================] 5ë¶„

ì²­í¬ ì²˜ë¦¬:
  Chunk 1: [========]
  Chunk 2:      [========]
  Chunk 3:           [========]
  Chunk 4:                [========]
  ...
  
Overlap:
  Chunk 1:     [======|==]
  Chunk 2:           [==|======]
                      â†‘
                  í¬ë¡œìŠ¤í˜ì´ë“œ
```

**íš¨ê³¼:**
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: **O(ì „ì²´ ê¸¸ì´) â†’ O(ì²­í¬ í¬ê¸°)**
- í’ˆì§ˆ: **Global Norm ë¬¸ì œ í•´ê²°**
- ì†ë„: ì•½ê°„ ì¦ê°€ (overlap ì—°ì‚°)

---

### 4.6 ë°ì´í„° ì¦ê°• (Augmentation)

#### **Pitch Shift**
```python
def pitch_shift(audio, n_steps):
    """
    ë°˜ìŒ(semitone) ë‹¨ìœ„ í”¼ì¹˜ ë³€ê²½
    
    Args:
        n_steps: -2 ~ +2 (ë°˜ìŒ)
    """
    return librosa.effects.pitch_shift(
        audio, sr=44100, n_steps=n_steps
    )

# í•™ìŠµ ì¤‘
audio = load_audio("song.wav")
if random.random() < 0.5:
    steps = random.randint(-2, 2)
    audio = pitch_shift(audio, steps)
```

**íš¨ê³¼:**
- ê°™ì€ ë…¸ë˜ë¥¼ ë‹¤ë¥¸ í‚¤(Key)ë¡œ í•™ìŠµ
- ìŒë†’ì´ ë¶ˆë³€ íŠ¹ì§• í•™ìŠµ
- **Demucs: +0.2 SDR**

---

#### **Tempo Shift**
```python
def tempo_shift(audio, rate):
    """
    í…œí¬ ë³€ê²½ (í”¼ì¹˜ ìœ ì§€)
    
    Args:
        rate: 0.8 ~ 1.2 (80% ~ 120% ì†ë„)
    """
    return librosa.effects.time_stretch(audio, rate=rate)
```

**íš¨ê³¼:**
- ë¹ ë¥¸/ëŠë¦° ë²„ì „ìœ¼ë¡œ í•™ìŠµ
- í…œí¬ ë¶ˆë³€ íŠ¹ì§• í•™ìŠµ
- **Demucs: +0.2 SDR**

---

#### **Combined Augmentation**
```python
def augment(audio):
    # 1. Pitch shift
    if random.random() < 0.5:
        audio = pitch_shift(audio, random.randint(-2, 2))
    
    # 2. Tempo shift
    if random.random() < 0.5:
        audio = tempo_shift(audio, random.uniform(0.8, 1.2))
    
    return audio
```

**ì´ íš¨ê³¼: +0.4 SDR**

---

#### **ëª¨ë¸ë³„ ì¦ê°• íš¨ê³¼ ë¹„êµ**

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° ìˆ˜ | Pitch/Tempo ì¦ê°• íš¨ê³¼ |
|------|------------|---------------------|
| Conv-Tasnet | ~5M | **-0.1 SDR** (ì—­íš¨ê³¼) |
| Demucs | ~33M | **+0.4 SDR** âœ… |

**ë¶„ì„:**
- **ì‘ì€ ëª¨ë¸**: ì¦ê°•ëœ ë°ì´í„°ë¥¼ ê³¼ì í•© ëª»í•¨ â†’ í˜¼ë€
- **í° ëª¨ë¸**: ì¦ê°•ëœ ë¶„í¬ë¥¼ ì œëŒ€ë¡œ í•™ìŠµ â†’ ì¼ë°˜í™” í–¥ìƒ

**êµí›ˆ:** 
> ë°ì´í„° ì¦ê°•ì˜ íš¨ê³¼ëŠ” ëª¨ë¸ capacityì— ì˜ì¡´ì 

---

## 5. ì‹¤í—˜ ë° ì„±ëŠ¥ ë¶„ì„

### 5.1 ë°ì´í„°ì…‹

#### **MUSDB18**
- **í¬ê¸°**: 150ê³¡ (í•™ìŠµ 100, ê²€ì¦ 50)
- **ì¥ë¥´**: Rock, Pop, Electronic ë“± ë‹¤ì–‘
- **í˜•ì‹**: 44.1kHz, ìŠ¤í…Œë ˆì˜¤
- **Ground Truth**: 4-stem ë¶„ë¦¬ëœ ì›ë³¸ ì œê³µ

#### **ì¶”ê°€ ë°ì´í„° (ë…¼ë¬¸ì˜ í™•ì¥ ì‹¤í—˜)**
- ë‚´ë¶€ ë°ì´í„°ì…‹ 800ê³¡
- ìë™ ë¶„ë¦¬ + í•„í„°ë§
- **íš¨ê³¼**: 6.3 â†’ 6.8 SDR

---

### 5.2 í‰ê°€ ì§€í‘œ

#### **SDR (Signal-to-Distortion Ratio)**
```python
def SDR(reference, estimated):
    """
    ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ (dB ë‹¨ìœ„)
    """
    noise = estimated - reference
    return 10 * log10(
        energy(reference) / energy(noise)
    )
```

**í•´ì„:**
- SDR 0 dB: ì‹ í˜¸ì™€ ë…¸ì´ì¦ˆê°€ ë™ì¼
- SDR 6 dB: ì‹ í˜¸ê°€ ë…¸ì´ì¦ˆì˜ 2ë°° (ê´œì°®ì€ ë¶„ë¦¬)
- SDR 10 dB: ì‹ í˜¸ê°€ ë…¸ì´ì¦ˆì˜ 10ë°° (í›Œë¥­í•œ ë¶„ë¦¬)

---

### 5.3 ì„±ëŠ¥ ë¹„êµ

#### **ì „ì²´ í‰ê·  SDR**

| ëª¨ë¸ | Drums | Bass | Vocals | Other | **í‰ê· ** |
|------|-------|------|--------|-------|---------|
| Open-Unmix | 5.3 | 5.2 | 6.3 | 4.0 | 5.2 |
| D3Net (ì´ì „ SOTA) | 6.0 | 5.6 | 6.9 | 4.5 | **6.0** |
| Conv-Tasnet | 5.7 | 5.4 | 6.2 | 4.3 | 5.4 |
| **Demucs** | **6.6** | **7.6** | **6.3** | **4.4** | **6.3** âœ… |
| Demucs + ë°ì´í„° | 7.0 | 8.2 | 6.8 | 4.8 | **6.8** |

---

#### **Bass ë¶„ë¦¬ì˜ íšê¸°ì  ì„±ê³¼**

```
ì´ë¡ ì  ìƒí•œ (IRM Oracle): 7.1 dB
Demucs ì‹¤ì œ ì„±ëŠ¥:        7.6 dB  ğŸš€

â†’ Oracleì„ 0.5 dB ì´ˆê³¼!
```

**ì˜ë¯¸:**
- Spectrogram ë§ˆìŠ¤í‚¹ì˜ **ì´ë¡ ì  í•œê³„ ëŒíŒŒ**
- Waveform ìƒì„±ì´ ë” ì •êµí•œ ë³µì› ê°€ëŠ¥
- íŠ¹íˆ ìœ„ìƒ ì •ë³´ê°€ ì¤‘ìš”í•œ ì €ìŒì—­ì—ì„œ ê°•ë ¥

---

#### **ì•…ê¸°ë³„ íŠ¹ì„± ë¶„ì„**

**Waveform (Demucs)ì´ ìœ ë¦¬í•œ ê²½ìš°:**
1. **Drums (6.6 dB)**
   - íƒ€ê²©ìŒì˜ sharpí•œ attack
   - ì •í™•í•œ ìœ„ìƒ í•„ìš”
   - ì‹œê°„ ë„ë©”ì¸ì´ ìì—°ìŠ¤ëŸ¬ì›€

2. **Bass (7.6 dB)**
   - ì €ì£¼íŒŒ ìœ„ìƒ ì •ë³´ ì¤‘ìš”
   - í„ìŠ¤ ê°™ì€ ì‹œê°„ íŒ¨í„´
   - Spectrogramì˜ ì£¼íŒŒìˆ˜ í•´ìƒë„ ë¶€ì¡±

**Spectrogramì´ ì—¬ì „íˆ ê°•í•œ ê²½ìš°:**
3. **Vocals (6.3 vs D3Net 6.9)**
   - ë°°ìŒ êµ¬ì¡°ê°€ ëª…í™•
   - ì£¼íŒŒìˆ˜ ë„ë©”ì¸ í‘œí˜„ì´ ìì—°ìŠ¤ëŸ¬ì›€
   - í¬ë¨¼íŠ¸(formant) íŠ¹ì§• í™œìš©

4. **Other (4.4 dB)**
   - ë‹¤ì–‘í•œ ì•…ê¸° í˜¼ì¬
   - ë³µì¡í•œ ìŒìƒ‰
   - ì—¬ì „íˆ ì–´ë ¤ìš´ ê³¼ì œ

---

### 5.4 Ablation Study (êµ¬ì„±ìš”ì†Œ ê¸°ì—¬ë„ ë¶„ì„)

| êµ¬ì„±ìš”ì†Œ | ì œê±° ì‹œ SDR | ê¸°ì—¬ë„ |
|---------|-----------|--------|
| **Full Demucs** | **6.3** | - |
| - LSTM | 5.9 | **-0.4** |
| - Skip Connections | 5.7 | **-0.6** |
| - GLU â†’ ReLU | 6.1 | **-0.2** |
| - Weight Rescaling | 5.8 | **-0.5** |
| - L1 â†’ L2 Loss | 6.2 | **-0.1** |

**í•µì‹¬ ë°œê²¬:**
1. **Skip Connections**ì´ ê°€ì¥ ì¤‘ìš” (-0.6)
2. **Weight Rescaling**ì´ í•„ìˆ˜ì  (-0.5)
3. **LSTM**ë„ ìƒë‹¹í•œ ê¸°ì—¬ (-0.4)

---

### 5.5 ì¶”ë¡  Trick íš¨ê³¼ ë¶„ì„

| ê¸°ë²• | ì¶”ë¡  ì‹œê°„ ë°°ìˆ˜ | SDR í–¥ìƒ | ì‹¤ìš©ì„± |
|------|--------------|---------|--------|
| Baseline | 1x | 6.3 | âœ… |
| + Shift Trick (N=10) | 10x | +0.3 = **6.6** | âš ï¸ |
| + Resampling | 3x | +0.2 = **6.5** | âš ï¸ |
| + Both | 30x | +0.4 = **6.7** | âŒ |

**ê¶Œì¥ ì‚¬í•­:**
- **ì‹¤ì‹œê°„ ì‘ìš©**: Baselineë§Œ
- **ê³ í’ˆì§ˆ í•„ìš”**: Shift Trickë§Œ
- **ìµœê³  í’ˆì§ˆ**: ë‘˜ ë‹¤ (ì˜¤í”„ë¼ì¸)

---

### 5.6 ì •ì„±ì  ë¶„ì„ (ì²­ì·¨ í…ŒìŠ¤íŠ¸)

**ì£¼ê´€ì  í‰ê°€ (5ì  ì²™ë„)**

| ëª¨ë¸ | ìì—°ìŠ¤ëŸ¬ì›€ | ì•„í‹°íŒ©íŠ¸ | ë¶„ë¦¬ ì •í™•ë„ | ì „ì²´ |
|------|----------|---------|-----------|------|
| Conv-Tasnet | 2.8 | 2.1 | 3.5 | 2.8 |
| D3Net | 3.9 | 3.8 | 3.7 | 3.8 |
| **Demucs** | **4.3** | **4.5** | **4.1** | **4.3** |

**ì£¼ìš” ë°œê²¬:**
1. **Conv-Tasnet**: ìˆ«ìëŠ” ê´œì°®ì§€ë§Œ "í‹±í‹±" ì†Œë¦¬, ê¸ˆì†ì„± ì•„í‹°íŒ©íŠ¸
2. **D3Net**: ì•ˆì •ì ì´ì§€ë§Œ ë² ì´ìŠ¤ê°€ ì•½í•¨
3. **Demucs**: ê°€ì¥ ìì—°ìŠ¤ëŸ½ê³  ê¹¨ë—í•œ ë¶„ë¦¬

---

## 6. ê²°ë¡  ë° ì¸ì‚¬ì´íŠ¸

### 6.1 í•µì‹¬ ê¸°ì—¬

#### **1. íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ ì¦ëª…**
> "Waveform ë„ë©”ì¸ ë”¥ëŸ¬ë‹ì´ Spectrogramì„ ëŠ¥ê°€í•  ìˆ˜ ìˆë‹¤"

- ê¸°ì¡´ í†µë…: Spectrogramì´ ì•ˆì •ì ì´ê³  ì„±ëŠ¥ ì¢‹ìŒ
- Demucs: ì ì ˆí•œ ì•„í‚¤í…ì²˜ + ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œ Waveformì´ ìš°ì›”

---

#### **2. í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ì˜ ì„±ê³µ**
```
CNN (U-Net)  +  RNN (LSTM)  =  ìµœê³  ì„±ëŠ¥
    â†“                â†“
ë¡œì»¬ ë””í…Œì¼      ê¸€ë¡œë²Œ ë¬¸ë§¥
```

**êµí›ˆ:**
- ë‹¨ì¼ ì•„í‚¤í…ì²˜ì˜ í•œê³„ ì¸ì‹
- ê°•ì  ì¡°í•©ì´ í•µì‹¬

---

#### **3. ì—”ì§€ë‹ˆì–´ë§ì˜ ì¤‘ìš”ì„±**

**ì„±ëŠ¥ í–¥ìƒ ë¶„í•´:**
```
ê¸°ë³¸ ì•„í‚¤í…ì²˜:        5.5 SDR
+ Weight Rescaling:  +0.5 â†’ 6.0
+ GLU:               +0.2 â†’ 6.2
+ Skip Connections:  +0.6 â†’ 6.8
- LSTM:              -0.5 â†’ 6.3 (ìµœì¢…)
+ ë°ì´í„° ì¦ê°•:        +0.4 â†’ 6.7
```

> ì„¸ë¶€ ìµœì í™”ê°€ ì„±ëŠ¥ì˜ 20%ë¥¼ ê²°ì •

---

#### **4. ë„ë©”ì¸ íŠ¹í™” ë°œê²¬**

| íŠ¹ì„± | Waveform ìœ ë¦¬ | Spectrogram ìœ ë¦¬ |
|------|--------------|-----------------|
| **ì•…ê¸°** | Drums, Bass | Vocals |
| **ì£¼íŒŒìˆ˜** | ì €ìŒì—­ | ì¤‘ê³ ìŒì—­ |
| **ì‹œê°„ íŠ¹ì„±** | Sharp attack | Sustained notes |
| **ìœ„ìƒ ì˜ì¡´ì„±** | ë†’ìŒ | ë‚®ìŒ |

**ë¯¸ë˜ ë°©í–¥:**
- í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸”
- ì•…ê¸°ë³„ ì „ë¬¸ ëª¨ë¸

---

### 6.2 í•œê³„ì  ë° ê°œì„  ë°©í–¥

#### **1. ê³„ì‚° ë¹„ìš©**
```
Conv-Tasnet: 5M parameters,  10 GFLOPs
Demucs:     33M parameters, 150 GFLOPs
```

**ê°œì„  ë°©í–¥:**
- ëª¨ë¸ ê²½ëŸ‰í™” (Pruning, Quantization)
- íš¨ìœ¨ì  LSTM ëŒ€ì²´ (Transformer?)

---

#### **2. Vocals ì„±ëŠ¥**
```
D3Net (Spectrogram): 6.9 dB
Demucs (Waveform):  6.3 dB  (-0.6)
```

**ê°€ì„¤:**
- ë³´ì»¬ì€ ë°°ìŒ êµ¬ì¡°ê°€ ëšœë ·
- ì£¼íŒŒìˆ˜ ë„ë©”ì¸ í‘œí˜„ì´ ë” ìì—°ìŠ¤ëŸ¬ì›€

**ê°œì„  ë°©í–¥:**
- Spectrogram branch ì¶”ê°€
- ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ

---

#### **3. ì‹¤ì‹œê°„ ì²˜ë¦¬**
```
5ë¶„ ë…¸ë˜ ì²˜ë¦¬ ì‹œê°„:
  Conv-Tasnet: ~2ë¶„ (GPU)
  Demucs:     ~8ë¶„ (GPU)
```

**ê°œì„  ë°©í–¥:**
- Streaming ì•„í‚¤í…ì²˜
- Causal convolution
- Online LSTM

---

### 6.3 ì‘ìš© ë¶„ì•¼

#### **1. ìŒì•… ì œì‘**
- ë¦¬ë¯¹ìŠ¤/ë§ˆìŠ¤í„°ë§
- ìƒ˜í”Œë§
- ê°€ë¼ì˜¤ì¼€

#### **2. ìŒì•… êµìœ¡**
- ì•…ê¸°ë³„ ì—°ìŠµ íŠ¸ë™ ìƒì„±
- ì±„ë³´ ë³´ì¡°

#### **3. ì €ì‘ê¶Œ / ë²•ì **
- í‘œì ˆ íƒì§€
- ìƒ˜í”Œë§ ë¶„ì„

#### **4. ìŒì•… ì •ë³´ ê²€ìƒ‰**
- ì•…ê¸°ë³„ ê²€ìƒ‰
- ì»¤ë²„ê³¡ íƒì§€

---

### 6.4 í›„ì† ì—°êµ¬ ë°©í–¥

#### **1. Demucs v2, v3 (ì‹¤ì œ ë°œí‘œë¨)**
- Transformer ë„ì…
- Multi-scale processing
- ì‹¤ì‹œê°„ ë²„ì „

#### **2. í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼**
```
Demucs (Waveform)  +  D3Net (Spectrogram)
         â†“                      â†“
      Ensemble Fusion
         â†“
    Best of both worlds
```

#### **3. Few-shot Learning**
- ìƒˆë¡œìš´ ì•…ê¸° ë¹ ë¥¸ ì ì‘
- ë©”íƒ€ ëŸ¬ë‹ í™œìš©

#### **4. ë¬´ê°ë… í•™ìŠµ**
- Ground truth ì—†ì´ í•™ìŠµ
- Unlabeled ë°ì´í„° í™œìš©

---

### 6.5 ìµœì¢… ì •ë¦¬

**Demucsì˜ í•µì‹¬ ë ˆì‹œí”¼:**

```
ğŸ§  ì•„í‚¤í…ì²˜
  â””â”€ U-Net (ë””í…Œì¼ ë³´ì¡´)
  â””â”€ Bi-LSTM (ë¬¸ë§¥ íŒŒì•…)
  â””â”€ GLU (ê²Œì´íŒ…)

âš™ï¸ ìµœì í™”
  â””â”€ Weight Rescaling (í•™ìŠµ ì•ˆì •ì„±)
  â””â”€ L1 Loss (íŒŒí˜• ë§¤ì¹­)
  â””â”€ Shift Trick (ì‹œë¶ˆë³€ì„±)

ğŸ“Š ë°ì´í„°
  â””â”€ Pitch/Tempo ì¦ê°•
  â””â”€ Chunking (ë©”ëª¨ë¦¬ íš¨ìœ¨)

ğŸ¯ ê²°ê³¼
  â””â”€ SOTA ë‹¬ì„± (6.3 SDR)
  â””â”€ Bass Oracle ì´ˆê³¼ (7.6 dB)
```

**í•œ ë¬¸ì¥ ìš”ì•½:**
> "ì ì ˆí•œ ì•„í‚¤í…ì²˜ ì„¤ê³„ì™€ ì„¸ì‹¬í•œ ì—”ì§€ë‹ˆì–´ë§ì„ í†µí•´ Waveform ë„ë©”ì¸ ë”¥ëŸ¬ë‹ì´ ìŒì•… ì†ŒìŠ¤ ë¶„ë¦¬ì˜ ìƒˆë¡œìš´ ì§€í‰ì„ ì—´ì—ˆë‹¤"

---

### 6.6 ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ

#### **ì–¸ì œ Demucsë¥¼ ì‚¬ìš©í• ê¹Œ?**

**âœ… ì‚¬ìš© ê¶Œì¥:**
- ë“œëŸ¼/ë² ì´ìŠ¤ ë¶„ë¦¬ ì¤‘ìš”
- ì˜¤í”„ë¼ì¸ ì²˜ë¦¬ ê°€ëŠ¥
- ê³ í’ˆì§ˆ ìš”êµ¬
- GPU ì‚¬ìš© ê°€ëŠ¥

**âŒ ì‚¬ìš© ë¹„ê¶Œì¥:**
- ì‹¤ì‹œê°„ í•„ìš”
- ë³´ì»¬ ë¶„ë¦¬ë§Œ í•„ìš”
- CPUë§Œ ì‚¬ìš©
- ê²½ëŸ‰í™” ì¤‘ìš”

#### **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ íŒ**

```python
# ê¸°ë³¸ ì„¤ì • (ë…¼ë¬¸)
config = {
    'channels': [64, 128, 256, 512, 1024, 2048],
    'kernel_size': 8,
    'stride': 4,
    'lstm_layers': 2,
    'depth': 6,
}

# ê²½ëŸ‰í™” ë²„ì „
config_light = {
    'channels': [32, 64, 128, 256, 512, 1024],  # ì ˆë°˜
    'depth': 5,  # 1 layer ê°ì†Œ
    'lstm_layers': 1,  # LSTM 1ê°œë§Œ
}
# ì„±ëŠ¥: ì•½ 5.8 SDR, ì†ë„: 3ë°° í–¥ìƒ
```

---
